{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamel19/INFO5731_FALL2020/blob/master/In_class_exercise_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 10/14/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvR_O9D8sOUY"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/Interesting_Code/rule-based.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPX2y-2MVzvb"
      },
      "source": [
        "import re \n",
        "import string \n",
        "import nltk \n",
        "import spacy \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import math \n",
        "from tqdm import tqdm \n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "# load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejjoaPsXW9aT"
      },
      "source": [
        "# load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dieGDe-rXBrK"
      },
      "source": [
        "# sample text \n",
        "text = \"The practice of data science often includes the use of cloud computing products.\" \n",
        "\n",
        "# create a spaCy object \n",
        "doc = nlp(text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvj1I6juXEbj",
        "outputId": "243d02df-3056-4cf8-be3a-aac1de1a70af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# print token, dependency, POS tag \n",
        "for tok in doc: \n",
        "  print(tok.text, \"-->\",tok.dep_,\"-->\", tok.pos_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The --> det --> DET\n",
            "practice --> nsubj --> NOUN\n",
            "of --> prep --> ADP\n",
            "data --> compound --> NOUN\n",
            "science --> pobj --> NOUN\n",
            "often --> advmod --> ADV\n",
            "includes --> ROOT --> VERB\n",
            "the --> det --> DET\n",
            "use --> dobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "cloud --> compound --> NOUN\n",
            "computing --> compound --> NOUN\n",
            "products --> pobj --> NOUN\n",
            ". --> punct --> PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd-VLILKgfh-"
      },
      "source": [
        "import lexnlp.extract.en.acts\n",
        "text = “Synopsis 1843””\n",
        "print(lexnlp.extract.en.acts.get_act_list(text))\n",
        "[{'location_start': None\n",
        "  'location_end': None\n",
        "  'section': 1\n",
        "  'year': 1843\n",
        "  'ambiguous': None\n",
        "  'act_name': 'Act'\n",
        "  'value': None }]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHSkMOhSikb1"
      },
      "source": [
        ">>> import lexnlp.extract.en.amounts\n",
        ">>> text = “the sum of thirty-seven hundred and seventy-seven 80-100 dollars”\n",
        ">>> print(list(lexnlp.extract.en.amounts.get_amounts(text)))\n",
        "[3700, 77.80]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0TBSY4riy6u"
      },
      "source": [
        "import lexnlp.extract.en.citations\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.citations.get_citations(text)))\n",
        "[(10, None, None, None, None, None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB94K5xfkao4"
      },
      "source": [
        ">>> import lexnlp.extract.en.entities.nltk_re\n",
        "\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.entities.nltk_re.get_entities.nltk_re(text)))\n",
        "[(None, None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx-IYCEpk5CL"
      },
      "source": [
        ">>> import lexnlp.extract.en.conditions\n",
        ">>> text = \"unless they should be relieved from their engagements as indorsers.\"\n",
        ">>> print(list(lexnlp.extract.en.conditions.get_conditions(text)))\n",
        "[('unless', None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGY5AeX_ls4m"
      },
      "source": [
        ">>> import lexnlp.extract.en.constraints\n",
        ">>> text = \"the levy had nothing more than a mere equitable right to redeem the cotton by paying the debts indorsed by the claimants.\"\n",
        ">>> print(list(lexnlp.extract.en.constraints.get_constraints(text)))\n",
        "[('more than', None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6jnUdJFpevy"
      },
      "source": [
        ">>> import lexnlp.extract.en.copyright\n",
        ">>> text = \"(C) Copyright 2019 Thomson Reuters\"\n",
        ">>> print(list(lexnlp.extract.en.copyright.get_copyright(text)))\n",
        "[('Copyright', '2019', 'Thomson Reuters')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwv9ZymCp4mY"
      },
      "source": [
        ">>> # Manually set court configuration data\n",
        ">>> import lexnlp.extract.en.courts\n",
        ">>> text = \"None\"\n",
        ">>> court_config_data = [entity_config(0, None, 0, None),\n",
        "    entity_config(1, \"None\", 0, [\"None\"])]\n",
        ">>> for entity, alias in lexnlp.extract.en.courts.get_courts(text, court_config_data):\n",
        "    print(\"entity=\", entity)\n",
        "    print(\"alias=\", alias)\n",
        "entity= (0, None, 0, [(None, None, False, None), (None, None, False, None)])\n",
        "alias= (None, None, False, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUvJkn5lrdam"
      },
      "source": [
        ">>> import lexnlp.extract.en.cusip\n",
        ">>> text = None\n",
        ">>> print(lexnlp.extract.en.cusip.get_cusip(text))\n",
        "[{'location_start': None,\n",
        "  'location_end': None,\n",
        "  'text': None,\n",
        "  'issuer_id': None,\n",
        "  'issue_id': None,\n",
        "  'checksum': None,\n",
        "  'ppn': None,\n",
        "  'tba': None,\n",
        "  'internal': None}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPE34SGprzpZ"
      },
      "source": [
        ">>> import lexnlp.extract.en.dates\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.dates.get_dates(text)))\n",
        "[datetime.date(None, None, None)]\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.dates.get_dates(text)))\n",
        "[datetime.date(None, None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUa7deoAsIRc"
      },
      "source": [
        ">>> import lexnlp.extract.en.definitions\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.definitions.get_definitions(text)))\n",
        "[None]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVZpnMmUs8L9"
      },
      "source": [
        ">>> import lexnlp.extract.en.distances\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.distances.get_distances(text)))\n",
        "[(None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDScsPAtMwA"
      },
      "source": [
        ">>> import lexnlp.extract.en.durations\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.durations.get_durations(text)))\n",
        "[('None', None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_7mitjItuW_"
      },
      "source": [
        ">>> import lexnlp.extract.en.money\n",
        ">>> text = \"amounting to upwards of fourteen thousand dollars.\"\n",
        ">>> print(list(lexnlp.extract.en.money.get_money(text)))\n",
        "[(14,000.0, 'USD')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YFa1v6ouSF_"
      },
      "source": [
        ">>> import lexnlp.extract.en.percents\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.percents.get_percents(text)))\n",
        "[(None, None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5s_nZmuw5v"
      },
      "source": [
        ">>> import lexnlp.extract.en.pii\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.pii.get_pii(text)))\n",
        "[(None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dysh-nLtvCPx"
      },
      "source": [
        ">>> import lexnlp.extract.en.ratios\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.ratios.get_ratios(text)))\n",
        "[(None, None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WQpxLivR4f"
      },
      "source": [
        ">>> import lexnlp.extract.en.regulations\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.regulations.get_regulations(text)))\n",
        "[(None, None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-y2M8uevmnz"
      },
      "source": [
        ">>> import lexnlp.extract.en.trademarks\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.trademarks.get_trademarks(text)))\n",
        "[None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mziroERzvmxK"
      },
      "source": [
        ">>> import lexnlp.extract.en.urls\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.urls.get_urls(text)))\n",
        "[None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrY4cUtyv-Yo"
      },
      "source": [
        ">>> import lexnlp.extract.en.addresses\n",
        ">>> text = None\n",
        ">>> print(list(lexnlp.extract.en.amounts.get_amounts(text)))\n",
        "[None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0pjgVZv-dt"
      },
      "source": [
        ">>> import lexnlp.extract.en.persons\n",
        ">>> text = \"C. J. Collier\"\n",
        ">>> print(list(lexnlp.extract.en.amounts.get_amounts(text)))\n",
        "[\"C.J. Collier\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-DhBAewZbl"
      },
      "source": [
        ">>> import lexnlp.extract.en.persons\n",
        ">>> text = \"J. Ormond\"\n",
        ">>> print(list(lexnlp.extract.en.amounts.get_amounts(text)))\n",
        "[\"J. Ormond\"]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}